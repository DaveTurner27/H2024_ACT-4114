---
output:
  pdf_document:
    includes:
      before_body: TP-title.tex
      in_header: preamble-latex.tex
---

\centering

\clearpage

\tableofcontents

```{=tex}
\justify  
\clearpage
```
```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache = TRUE, message = FALSE, warning = FALSE)
```

```{r paquetages, message=FALSE, warning=FALSE, eval=TRUE, include=FALSE, echo = FALSE}
### Liste des paquetages
liste.paquetage <- c("ggplot2", "FactoMineR", "pls", "mice", "car", "MASS",
                     "glmnet", "caret", "FNN", "dplyr", "rpart", "rpart.plot", "tidyverse",
                     "Matrix", "data.table")

### On installe les paquetages de la liste qu'on a pas déjà
inst <- liste.paquetage %in% installed.packages()
if(length(liste.paquetage[!inst]) > 0) install.packages(liste.paquetage[!inst])

l <- lapply(liste.paquetage, require, character.only = TRUE)
```

```{r import}
train.dat <- read.csv("train.csv")[, -1]
test <- read.csv("test.csv")[, -1]

for(idx in c("Gender", "Type", "Category",
             "Occupation", "Adind", "Region", "Is_18")){
    train.dat[, idx] <- factor(train.dat[, idx])
    test[, idx] <- factor(test[, idx])
}

# Déviance poisson
dev.pois <- function(preds, clnb){
  2*sum(clnb*log((clnb+ 1E-10)/preds)-(clnb-preds))
}
```

# Introduction

La tarification en assurance de dommage est un processus complexe et intéressant. Il est souvent nécessaire et plus efficace de séparer le processus de modélisation du risque en deux parties. La première partie est la fréquence des sinistres. Cette partie de la modélisation est cruciale, puisque c'est elle qui nous permet de prévoir le nombre de réclamations qu'aura une personne assurée durant la durée de sa police. Il est donc essentiel de savoir comment modéliser efficacement et le plus précisément possible la fréquence en assurance de dommage.

Dans ce rapport, on modélise la fréquence des réclamations pour la responsabilité civile (dommages matériels) en assurance automobile. Nos données représentent un portefeuille d'assurés français. Dans le tableau de données original on retrouve :

-   la variable réponse $N$, qui est nommée `Numtppd`;

-   la variable d'exposition $365 t$ (nombre de jours de couverture) sous le nom `Exppdays`. Elle est renommée `Expp` après modification pour représenter la proportion d'année couverte : $t =$ `Exppdays` / 365 jours.

Plusieurs modèles seront étudiés pour modéliser la variable réponse :

-   *GLM* (modèle de référence);

-   *GLM* avec régularisation;

-   Modèle des k plus proches voisins;

-   Arbre de décision;

-   *Bagging;*

-   Forêt aléatoire;

-   *Gradient Boosting.*

En ce qui concerne le jeu de données, il est disponible directement en `R` dans le paquetage `CASdatasets`. Plus précisément, il s'agit du jeu de données `pg15training`. Les données ont été utilisées par l'Institut française des actuaires dans un concours/jeu de tarification. Elles proviennent d'assureurs automobiles privés inconnus. La matrice contient 2 ans d'observations (2009 et 2010) avec 50 000 observations dans chacune de ces deux années.

Pour plus d'information sur les données, il est possible d'aller voir la documentation sur CRAN ou bien simplement de faire la commande suivante en `R` : `help(pg15train.dating)`.

À noter que des modifications ont été faites sur le jeu de données, celles-cis sont documentées dans le premier rapport (Analyse préparatoire).

Dans ce rapport on présentera d'abord un modèle de base (GLM). Ensuite, on parlera des autres modèles étudiés en détaillant la procédure utilisée pour les ajuster. Par la suite, tous les modèles étudiées seront comparer. On interprétera ensuite les deux modèles les plus prometteurs. Enfin, on proposera un choix de modèle finale. Les lecteurs intéressés par la recommandation finale peuvent passer directement à la section conclusion.

# Modèle de base

```{r base_mod}
formula_base <- formula(
    Numtppd ~ Gender + Type + Occupation +
         + I(Age^2)+I(Age^3)+I(Age^4)+
        I(Age^5)+I(Age^6)+I(Age^7)+
        Bonus + Poldur + Density + Region + log(Power) +
        offset(I(log(Expp)))
)
mod.base <- glm(
    formula = formula_base,
    family = poisson(link = "log"),
    data = train.dat
)
prev_test.base <- predict(mod.base, newdata=test, type="response")
deviance.base <- dev.pois(prev_test.base, test$Numtppd)
```

Après avoir séparé les données en deux échantillons : `train` (85 % des données) et `test` (15 % des données), on est prêt à construire le modèle de base. On fait face à un problème de régression et la variable réponse est discrète. La loi de Poisson, la loi Binomiale Négative et la de Poisson gonflée à zéro sont toutes de bonnes possibilités pour construire un modèle linéaire généralisé sur des données de comptages.

En revanche, le modèle choisi est le modèle de Poisson. On fait ce choix, car ce modèle est le plus simple ce qui est idéale pour un modèle de base. Le modèle est donc un GLM Poisson avec fonction de lien logarithmique.

Avec notre rapport 1 on a vu qu'il pourrait être intéressant d'utilises la variable âge jusqu'au degré 7 (âge, âge$^2, \dots$, âge$^7$). En fait, cette technique semble effectivement efficace, puisqu'après la sélection de variable, on conserve les 7 variables. Pour la sélection des variables, on a fait une analyse de déviance au seuil de confiance 99 % en utilisant la méthode algorithmique *Backward*. C'est donc un modèle simple, mais celui-ci demeure un référence fiable pour la suite.

# Ajustement des modèles

## Régression régularisée Lasso

```{r Lasso, message=FALSE, warning=TRUE}
# Mod sans reg
mod.complet <- glm(Numtppd ~.+I(Age^2)+I(Age^3)+I(Age^4)+I(Age^5)+I(Age^6)+
                       I(Age^7)-Expp-Power+I(log(Power)),
                   family = poisson, data = train.dat)

# Data
x.train <- model.matrix(mod.complet, data = train.dat)[, -1]
y.train <- train.dat$Numtppd
x.test <- model.matrix(mod.complet, data = test)[, -1]

# lambda
# set.seed(111)
# cv.out <- cv.glmnet(
#     x.train, y.train, offset = I(log(train.dat$Expp)),
#     alpha = 1, nfolds = 10, family = "poisson", 
# )
# meilleur.lam.lasso <- cv.out$lambda.min
# mod.lasso <- glmnet(x.train, y.train, family = "poisson",
#                     alpha = 1, lambda = meilleur.lam.lasso, offset = log(train.dat$Expp))
```

```{r rds_lasso}
# saveRDS(list(
#     cv.out=cv.out,
#     meilleur.lam.lasso=meilleur.lam.lasso,
#     mod.lasso=mod.lasso), "lasso")
lasso <- readRDS("lasso")
cv.out <- lasso$cv.out
meilleur.lam.lasso <- lasso$meilleur.lam.lasso
mod.lasso <- lasso$mod.lasso

# Prév
prev_test.lasso <- exp(predict(mod.lasso, newx = x.test, newoffset = I(log(test$Expp))))
deviance.lasso <- dev.pois(prev_test.lasso, test$Numtppd)
```

Ici, on construit un modèle de régression régularisée *Lasso*. La distribution utilisée est encore une loi de Poisson. Le lien utilisé est le lien log. On rappelle qu'on utilise encore une régression polynomiale de degré 7 sur l'âge.

L'avantage de la régression régularisée *Lasso* est que la sélection des variables explicatives est fait pour nous. La fonction *Score* de la régression est :

$$ S^{Lasso}(\beta) = -l(\beta)/n + \lambda  \sum_{j = 1}^p | \beta_j|. $$

Le vecteur $\beta$ est le vecteur de paramètres qui sera estimé par maximum de vraisemblance. La fonction $l(\beta)$ est la fonction de log-vraisemblance. La variable $n$ est le nombre d'observations dans l'échantillon d’entraînement et la variable $p$ est le nombre de variables explicatives.

Pour ce qui est de l'hyperparamètre $\lambda$, il est choisi par validation croisée avec 10 plis. Cet hyperparamètre est choisi de façon à minimiser la déviance de Poisson moyenne de la validation croisée. Sa valeur est de `r meilleur.lam.lasso`. La figure ci-dessous montre comment cette valeur est sélectionnée.

```{r fig_lam_lasso, fig.cap="Optimisation de de l'hyperparamètre lambda (Lasso)", fig.align = "center", fig.height=3.6}
ggplot(mapping = aes(x=log(cv.out$lambda), y=cv.out$cvm)) + geom_point() + geom_line() + theme_bw() +
    labs(title="Déviance moyenne en fonction de lambda (Lasso)",
         x="log(lambda)", y="Déviance moyenne")
```

## k plus proches voisins

```{r knn_optimise_k, include=FALSE}

iter <- 30
k <- seq(75, 105, 5)
    keep.cols <- c("Numtppd", "Expp", "Age",
                   "Bonus", "Poldur", "Value",
                   "Density", "Power")
# resultats.knn <- matrix(nrow = iter, ncol = length(k))
# 
# set.seed(55)
# for(i in 1:iter){
# 
#     # Création du jeu de validation
#     p <- 0.3
#     idx_not0 <- which(train.dat$Numtppd > 0)
#     idx_0 <- which(train.dat$Numtppd == 0)
#     ind.val <- c(
#         sample(idx_0, round(p*length(idx_0))),
#         sample(idx_not0, round(p*length(idx_not0))))
#     dat.valid <- train.dat[ind.val, keep.cols]
#     dat.non.valid <- train.dat[-ind.val, keep.cols]
# 
#     # initier la boucle
#     idx <- 0
# 
#     for(k_neib in k){
# 
#         idx <- idx + 1
# 
#         # fit knn
#         fit <- knn.reg(
#             train = dat.non.valid[, -c(1, 2)],
#             y = dat.non.valid$Numtppd / dat.non.valid$Expp,
#             test = dat.valid[, -c(1, 2)],
#             k = k_neib)
# 
#         # Prev
#         prevs <- fit$pred * dat.valid$Expp + 1E-4
#         resultats.knn[i, idx] <- dev.pois(preds = prevs, clnb = dat.valid$Numtppd)
#     }
# }
```

```{r RDS_knn}
# saveRDS(resultats.knn, "knn")
resultats.knn <- readRDS("knn")

# Faire les prév test
train.knn <- train.dat[, keep.cols]
test.knn <- test[, keep.cols]

fit_knn_test <- knn.reg(
    train = train.knn[, -c(1, 2)],
    y = train.knn$Numtppd / train.knn$Expp,
    test = test.knn[, -c(1, 2)],
    k = k[which.min(colMeans(resultats.knn))])

prev_test.knn <- fit_knn_test$pred * test$Expp + 1E-4
deviance.knn <- dev.pois(prev_test.knn, test.knn$Numtppd)
```

```{r fig_knn, fig.cap="Optimisation de de l'hyperparamètre k (knn)", fig.align = "center", fig.height=3.6}
ggplot(mapping = aes(x=k, y=colMeans(resultats.knn))) + geom_point() + 
     geom_point(aes(x=k[which.min(colMeans(resultats.knn))]),
               y=min(colMeans(resultats.knn)), size=4, col="orange", alpha=0.6)+
    geom_line() + theme_bw() + 
    labs(y="Moyenne des déviances\ndes échantillons  de validations", x="Nombre de voisins (k)",
         title = "Déviance moyenne en fonction de k (knn)")
```

## Arbre de décision

```{r arbre, message=FALSE, warning=FALSE}
set.seed(2019)
tree.control <- rpart.control(
    cp = 0,
    minbucket = 150L,
    xval = 10L)

arbre <- rpart(
    cbind(Expp, Numtppd)~.,
    method = "poisson",
    data = train.dat,
    control = tree.control, parms = list(shrink=1))

# Meilleur cp
err.min <- arbre$cptable[which.min(arbre$cptable[,4]),]
err.max <- err.min[4] + err.min[5]
cp.pois <- max(arbre$cptable[arbre$cptable[,4] <= err.max,1])
# cp.pois <- arbre$cptable[which.min(arbre$cptable[,4]), 1]

mod.arbre <- prune(arbre, cp = cp.pois)
prev_test.arbre <- predict(mod.arbre, newdata=test)
deviance.arbre <- dev.pois(prev_test.arbre, test$Numtppd)
```

On construit maintenant un arbre de régression Poisson. On choisi la déviance de la loi Poisson comme fonction de perte. Ce choix est assez intuitif étant donné que nous sommes en présence de données de comptage.

Avant de faire un arbre il faut choisir le coefficient de variation de la distribution à priori $(\gamma)$. On décide de garder la valeur par défaut que `R` nous suggère pour cet hyperparamètre, puisque de toute façon ce dernier ne devrait pas influencer la performance du modèle de manière significative.

On procède ensuite par validation croisée à 10 plis pour trouver la valeur idéale du cp. On chosit le cp qui donne la plus petite déviance moyenne de la validation croisée. En fait, on choisit la plus grande valeur qui est en dessous de la valeur minimale + 1 écart type. La valeur idéale trouvée est de `r cp.pois`. Avec cette valeur on peut obtenir l'arbre final.

```{r fig_cp_arbre}
plotcp(arbre, upper = "none", col = "orange", lty = 1, pch=16, cex=0.5, ylim=c(0.8, 0.9), main="Erreur relative de la validation croisée en fonction du cp")
```

## Bagging

```{r optimisation_minbucket_bag, include=FALSE}

# set.seed(154)
minb <- seq(0, 225, 25)

# Optimiser minbucket
resultats.bag <- numeric(length(minb))

# idx <- 0
# for(i in minb){
# 
#     idx <- idx + 1
# 
#     # Construire la foret
#     foret.node <- distRforest::rforest(
#         cbind(Expp, Numtppd)~.,
#         method="poisson",
#         data=train.dat,
#         control=rpart.control(
#             minbucket = i,
#             cp=0,
#             xval = 1
#         ),
#         ncand=13,
#         ntrees = 200,
#         subsample = 1,
#         track_oob = TRUE)
# 
#     # Ajout de la deviance
#     resultats.bag[idx] <- tail(foret.node$oob, 1)
# }
```

```{r optimisation_tree_bag, include=FALSE}
# # Optimiser nombre d'arbres
# mod.bag <- distRforest::rforest(
#         cbind(Expp, Numtppd)~.,
#         method="poisson",
#         data=train.dat,
#         control=rpart.control(
#             minbucket = minb[which.min(resultats.bag)],
#             cp=0,
#             xval = 1
#         ),
#         ncand=13,
#         ntrees = 200,
#         subsample = 1,
#         track_oob = TRUE)
```

```{r RDS_bag}

# # Save
# saveRDS(
#     list(
#         resultats.bag=resultats.bag,
#         mod.bag=mod.bag
#     ), "bagging"
# )

# Read
bagging <- readRDS("bagging")
resultats.bag <- bagging$resultats.bag
mod.bag <- bagging$mod.bag

# Prev bag
prev_test.bag <- distRforest::predict.rforest(mod.bag, newdata = test)
deviance.bag <- dev.pois(preds = prev_test.bag, clnb = test$Numtppd)
```

```{r fig_minb_bag}
ggplot(mapping = aes(x=minb[-1], y=resultats.bag[-1])) +
    geom_point() + geom_line() +
    geom_point(aes(x=minb[which.min(resultats.bag)]),
               y=min(resultats.bag), size=4, col="orange", alpha=0.6) +
    theme_bw() +
        labs(title = "Déviance moyenne OOB en fonction de 'minbucket'",
             x="minbucket", y="Déviance moyenne OOB")
```

```{r fig_tree_bag}
ggplot(mapping = aes(x=seq(10, 200, 10), y=mod.bag$oob_error[seq(10, 200, 10)])) + geom_line() + geom_point() + theme_bw() +
    labs(title = "Déviance moyenne OOB en fonction du nombre d'arbres", x="Nombre d'arbres", y="Déviance moyenne OOB")
```

## Forêt aléatoire

```{r optimisation_foret, include=FALSE}
# set.seed(7815)

# Valeurs à tester
ncand <- 3:11
minb.foret <- c(20, 40, 60, 80)

# # initialisation boule
# resultats.foret <- data.frame(ncand=ncand)
# idx_j  <- 0
# 
# for(j in minb.foret){
# 
#     idx_j  <- idx_j + 1
# 
#     # Optimiser ncand
#     prev.ncand <- numeric(length(ncand))
# 
#     idx_i <- 0
#     for(i in ncand){
# 
#         idx_i <- idx_i + 1
# 
#         # Construire la foret
#         foret <- distRforest::rforest(
#             cbind(Expp, Numtppd)~.,
#             method="poisson",
#             data=train.dat,
#             control=rpart.control(
#                 minbucket = j,
#                 cp=0,
#                 xval = 1
#             ),
#             ncand=i,
#             ntrees = 125,
#             subsample = 0.5,
#             track_oob = TRUE)
# 
#         # Ajout de l'erreur
#         prev.ncand[idx_i] <- tail(foret$oob_error, 1)
#     }
#     resultats.foret[, as.character(j)] <- prev.ncand
# }
# 
# # Reshape the data
# resultats.foret <- resultats.foret %>%
#   pivot_longer(cols = 2:ncol(resultats.foret),
#                names_to = "minb",
#                values_to = "Erreur")
```

```{r foret_final, include=FALSE}
# set.seed(4230)
# mod.foret <- distRforest::rforest(
#         cbind(Expp, Numtppd)~.,
#         method="poisson",
#         data=train.dat,
#         control=rpart.control(
#             minbucket = as.numeric(
#                 resultats.foret[which.min(resultats.foret$Erreur), ]$minb),
#             cp=0,
#             xval = 0
#         ),
#         ncand=as.numeric(
#             resultats.foret[which.min(resultats.foret$Erreur), ]$ncand),
#         ntrees = 150,
#         subsample = 0.5,
#         track_oob = T)
```

```{r RDS_foret}

# # Save
# saveRDS(
#     list(
#         mod.foret=mod.foret,
#         resultats.foret=resultats.foret
#     ), "foret"
# )

# Read
foret <- readRDS("foret")
resultats.foret <- foret$resultats.foret
mod.foret <- foret$mod.foret

# Prev foret
prev_test.foret <- distRforest::predict.rforest(mod.foret, newdata = test)
deviance.foret <- dev.pois(preds = prev_test.foret, clnb = test$Numtppd)
```

```{r fig_optim_foret}
ggplot(resultats.foret, mapping = aes(x=ncand, y=Erreur, col=minb)) +
    geom_point(size=2, alpha=0.6) + geom_line(linewidth=1) + theme_bw() + theme(legend.position = "bottom") +
    scale_x_continuous(breaks = seq(min(resultats.foret$ncand), max(resultats.foret$ncand), by = 1))+
    labs(title = "Optimisation des hyperparamètres 'm' et 'MinBucket'", x="Nombre de varible candidates (m)",
         y="Déviance moyenne OOB", col="Minimum d'obs. par feuille :")
```

## Gradient Boosting

```{r}
deviance.boost <- 8000
```

# Comparaison des modèles

```{r table deviance}
dev.df <- data.frame(
    Modèle = c(
        "Base (GLM)", "Lasso", "knn",
        "Arbre", "Bagging",
        "RF", "Boost"
    ),
    Déviance=c(
        deviance.base, deviance.lasso,deviance.knn,
        deviance.arbre, deviance.bag,
        deviance.foret, deviance.boost)
)
dev.df <- dev.df[order(dev.df$Déviance), ]
knitr::kable(dev.df, format = "markdown", digits = 0, row.names = FALSE, align = "c", 
             label = "Déviance Poisson des modèle sur l'échantillon Test")
```

```{r fonctions_graphs}

# double lift curve graph
double_lift <- function(actual, ref, pred, mod.names=c("REF", "PRED"), k=4){

    # Préparation
    idx.order <- order(pred/ref)
    n <- length(ref)
    # normalisé
    ref <- ref * mean(actual) / mean(ref)
    pred <- pred * mean(actual) / mean(pred)

    # Sort
    ref <- ref[idx.order]
    pred <- pred[idx.order]
    actual <- actual[idx.order]
    data <- data.frame(
        FIGURE=c(ref, pred),
        Model=as.factor(c(rep(mod.names[1], n), rep(mod.names[2], n)))
    )

    # Cut
    data$GROUPE <- rep(cut(1:n, k, labels = F), 2)

    # LR
    sum_actual <- sapply(split(actual, cut(1:n, k, labels = F)), sum)
    data <- data %>%
        group_by(Model, GROUPE) %>%
        summarise(LR = sum(FIGURE))
    data$LR <- sum_actual / data$LR

    # Graphique
    p <- ggplot(data, aes(x=GROUPE, y=LR, col=Model)) +
        geom_point(size=2.25) + geom_line(linewidth=1) +
        geom_hline(yintercept = 1, linewidth=0.3, col="black", alpha=0.4)+
        labs(title = "", y="Ratio", x="Groupe") + theme_bw()
    print(p)
}

impact_analysis <- function(actual, ref, pred, mod.names=c("REF", "PRED"), k=4){

    # Préparation
    idx.order <- order(ref)
    n <- length(ref)
    # normalisé
    ref <- ref * mean(actual) / mean(ref)
    pred <- pred * mean(actual) / mean(pred)

    # Sort
    ref <- ref[idx.order]
    pred <- pred[idx.order]
    actual <- actual[idx.order]
    data <- data.frame(
        FIGURE=c(ref, pred, actual),
        Model=as.factor(c(rep(mod.names[1], n), rep(mod.names[2], n), rep("Vraie valeur", n)))
    )

    # Cut
    data$GROUPE <- rep(cut(1:n, k, labels = F), 3)

    # Moyenne
    data <- data %>%
        group_by(Model, GROUPE) %>%
        summarise(MOYENNE = mean(FIGURE))

    # Graphique
    p <- ggplot(data, aes(x=GROUPE, y=MOYENNE, col=Model)) +
        geom_point(size=2.25) + geom_line(linewidth=1) + labs(title = "Impact analysis", y="Moyene de sinistre", x="Group") + theme_bw()
    print(p)
}
```

```{r}
double_lift(actual = test$Numtppd, ref = prev_test.base, pred = prev_test.arbre, mod.names = c("GLM", "Arbre"), k=5)
impact_analysis(actual = test$Numtppd, ref = prev_test.base, pred = prev_test.arbre, mod.names = c("GLM", "Arbre"), k=5)
```

# Interprétation des meilleurs modèles

# Conclusion

# Bibliographie
