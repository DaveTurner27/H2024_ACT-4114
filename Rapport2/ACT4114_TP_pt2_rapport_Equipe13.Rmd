---
output:
  pdf_document:
    includes:
      before_body: TP-title.tex
      in_header: preamble-latex.tex
---

\centering

\clearpage

\tableofcontents

```{=tex}
\justify  
\clearpage
```
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r paquetages, message=FALSE, eval=TRUE, include=FALSE, echo = FALSE}
### Liste des paquetages
liste.paquetage <- c("ggplot2", "FactoMineR", "pls", "mice", "car", "MASS",
                     "glmnet", "caret", "FNN", "dplyr")

### On installe les paquetages de la liste qu'on a pas déjà
inst <- liste.paquetage %in% installed.packages()
if(length(liste.paquetage[!inst]) > 0) install.packages(liste.paquetage[!inst])

l <- lapply(liste.paquetage, require, character.only = TRUE)
```

```{r import}
train <- read.csv("train.csv")[, -1]
test <- read.csv("test.csv")[, -1]
```

# Introduction

On modélise la fréquence des réclamations pour la responsabilité civile (dommages matériels) en assurance automobile. Nos données représentent un portefeuille d'assurés français. Dans le tableau de données original on retrouve :

-   la variable réponse $N$ est nommée `Numtppd`;

-   la variable d'exposition $365 t$ (nombre de jours) sous le nom `Exppdays`. Elle est renommée `Expp` après modification pour représenter le ratio `Exppdays` / 365 jours.

Plusieurs modèles seront étudiés :

-   GLM (modèle de référence);

-   GLM avec régularisation;

-   Modèle des k plus proches voisins;

-   Arbre de décision;

-   *Bagging;*

-   Forêt aléatoire;

-   *Gradient Boosting.*

En ce qui concerne le jeu de données, il est disponible directement en `R` dans le paquetage `CASdatasets`. Plus précisément, il s'agit du jeu de données `pg15training`. Les données ont été utilisées par l'Institut française des actuaires dans un concours/jeu de tarification. Elles proviennent d'assureurs automobiles privés inconnus. La matrice contient 2 ans d'observations (2009 et 2010) avec 50 000 observations dans chacune de ces deux années.

Pour plus d'information sur les données, il est possible d'aller voir la documentation sur CRAN ou bien simplement de faire la commande suivante en `R` : `help(pg15training)`.

# Modèle de base

Après avoir séparé les données en deux ensembles : `train` (85 % des données) et `test` (15 % des données), on est prêt à construire le modèle de base. On fait face à un problème de régression et la variable réponse est discrète. La loi de Poisson, la loi Binomiale Négative et la de Poisson gonflée à zéro sont toutes de bonnes possibilités pour construire un modèle linéaire généralisé sur des données de comptages.

Après avoir essayé ces options, le modèle choisi est le modèle de Poisson. On fait ce choix, car ce modèle est plus simple et la statistique d'AIC est similaire pour les trois options. Le modèle choisi est donc un GLM Poisson avec fonction de lien logarithmique. Pour la sélection des variables, on fait une analyse de déviance au seuil de confiance 99 % en utilisant le méthode *Backward*.

# Ajustement des modèles

## Régressions régularisées

```{r regularisé}
mod.complet <- glm(Numtppd ~.-Expp+offset(Expp), family = poisson, data = train)
# summary(mod.complet)
x.train <- model.matrix(mod.complet, data = train)[, -1]
y.train <- train$Numtppd

# lambda
grid.lambda <- 10^seq(3, -2, length = 100)
mod.lasso <- glmnet(x.train, y.train, family = "poisson", alpha = 1, lambda = grid.lambda)
set.seed(111)
cv.out <- cv.glmnet(x.train, y.train, alpha = 1, nfolds = 3)
# plot(cv.out)
meilleur.lam.lasso <- cv.out$lambda.min
# predict(mod.lasso, type = "coefficients", s = meilleur.lam.lasso)
x.test <- model.matrix(mod.complet, data = test)[, -1]
pred_lasso <- predict(mod.lasso, newx = x.test, s = meilleur.lam.lasso, type = "response")
# MSE
mse_lasso <- mean((pred_lasso - test$Numtppd)^2)

# POUR RIDGE
mod.ridge <- glmnet(x.train, y.train, family = "poisson", alpha = 0, lambda = grid.lambda)
set.seed(111)
cv.out2 <- cv.glmnet(x.train, y.train, alpha = 0, nfolds = 3)
# plot(cv.out2)
meilleur.lam.ridge <- cv.out2$lambda.min
# predict(mod.ridge, type = "coefficients", s = meilleur.lam.ridge)
pred_ridge <- predict(mod.ridge, newx = x.test, s = meilleur.lam.ridge, type = "response")
# MSE
mse_ridge <- mean((pred_ridge - test$Numtppd)^2)
```

Ici on construit des GLM régularisées. On construit un modèle de régression *Ridge* et *Lasso*.

### Lasso

La distribution utilisée est encore une loi de Poisson avec fonction de lien logarithmique. L'avantage ici est que ce type de régression fait la sélection des variables explicatives. La fonction *Score* de la régression est :

$$ S^{Lasso}(\beta) = -\mathcal{l}(\beta)/n + \lambda  \sum_{j = 1}^p | \beta_j|. $$

Le vecteur $\beta$ est un vecteur de paramètres qui sera estimé par maximum de vraisemblance. Pour ce qui est de l'hyperparamètre $\lambda$ est choisi par validation croisée avec 3 plis. Cet hyperparamètre est choisi pour minimiser l'erreur quadratique moyenne de la validation croisée. Sa valeur est de `r meilleur.lam.lasso`

### Ridge

La procédure est identique à la régression *Ridge*, mais la fonction *Score* de la régression est :

$$
S^{Ridge}(\beta) = -\mathcal{l}(\beta)/n  + \lambda \sum_{j = 1}^p \beta_j^2.
$$

L'hyperparamètre $\lambda$ optimal est `r 2 * meilleur.lam.ridge`

### Résumé

Étant donné que la performance de l'erreur quadratique moyenne sur l'ensemble de test est très similaire entre ces deux modèles. On décide de poursuive l'analyse avec la régression de *Lasso* puisqu'elle fait la sélection de variable et que ce modèle est plus simple.

## k plus proches voisins

## Arbre de décision

## Bagging

## Forest aléatoire

## Gradient Boosting

# Comparaison des modèles

# Interprétation des meilleurs modèles

# Conclusion

# Bibliographie
